{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Анализ-данных\" data-toc-modified-id=\"Анализ-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Анализ данных</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подгтовка-и-работа-с-выборками\" data-toc-modified-id=\"Подгтовка-и-работа-с-выборками-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подгтовка и работа с выборками</a></span></li><li><span><a href=\"#Обучение-и-тестирование-моделей\" data-toc-modified-id=\"Обучение-и-тестирование-моделей-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение и тестирование моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import stopwords as сс\n",
    "\n",
    "nltk.download('wordnet','stopwords','punkt','averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубликаты\n",
    "data.duplicated().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пропуски\n",
    "data.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#соотношение в целевом признаке\n",
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю столбец Unnamed\n",
    "data = data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нижний регистр\n",
    "data['text'] = data['text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# буквы в нижнем и верхнем регистре + цифры\n",
    "data_new = []\n",
    "pattern = r'[^a-zA-Z0-9]' #r'[^a-zA-z]' [^a-zA-Z0-9]\n",
    "for sentence in data.text:\n",
    "  cleared_text = re.sub(pattern, \" \", sentence)\n",
    "  data_new.append(\" \". join(cleared_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation\\nwhy the edits made under my usern...      0   \n",
       "1  d'aww! he matches this background colour i'm s...      0   \n",
       "2  hey man, i'm really not trying to edit war. it...      0   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "4  you, sir, are my hero. any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"clear_text\"]=data_new\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сэмплирую\n",
    "sample_size = 90000\n",
    "corpus = data.sample(n=sample_size,random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизациия и лемматизация массива текстов\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizered(corpus):\n",
    "  \n",
    "  corpus_new = []\n",
    "  for sentence in corpus:\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "    corpus_new.append(' '.join([lemmatizer.lemmatize(w) for w in word_list]))\n",
    "  return corpus_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  словарь, где возвращается значение часть речи \n",
    "def get_wordnet_pos(word):\n",
    "    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    " \n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизациия и лемматизация массива текстов c учетом pos_tag и удаление стоп-слов\n",
    "def get_word_text(corpus):\n",
    "  \n",
    "  corpus_new = []\n",
    "  for sentence in corpus:\n",
    "    corpus_new.append(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence) if not w in nltk_stopwords.words('english')]))\n",
    "  return corpus_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лемматизация корпуса c учетом pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 7s, sys: 1min 59s, total: 18min 7s\n",
      "Wall time: 18min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    " \n",
    "corpus['clear_text_2'] = get_word_text(corpus['clear_text']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>clear_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\nwell, since i am blocked, i shall temporari...</td>\n",
       "      <td>0</td>\n",
       "      <td>well since i am blocked i shall temporarily re...</td>\n",
       "      <td>well since block shall temporarily respond whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nhahahahaha. typical. \\n\\nthe article is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>hahahahaha typical the article is about anti p...</td>\n",
       "      <td>hahahahaha typical article anti pedophile acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which you made after i was encouraged by a med...</td>\n",
       "      <td>0</td>\n",
       "      <td>which you made after i was encouraged by a med...</td>\n",
       "      <td>make encourage mediator admin make one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i regard you a racist. i will request you be b...</td>\n",
       "      <td>1</td>\n",
       "      <td>i regard you a racist i will request you be ba...</td>\n",
       "      <td>regard racist request ban life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\na broken chair is not a chair\\na broken c...</td>\n",
       "      <td>0</td>\n",
       "      <td>a broken chair is not a chair a broken chord i...</td>\n",
       "      <td>broken chair chair broken chord chord invert p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>now that you let screwattack how about you fuc...</td>\n",
       "      <td>1</td>\n",
       "      <td>now that you let screwattack how about you fuc...</td>\n",
       "      <td>let screwattack fuck pedant wikipedia asshole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>national geographic \\n\\nwhy is there no mentio...</td>\n",
       "      <td>0</td>\n",
       "      <td>national geographic why is there no mention in...</td>\n",
       "      <td>national geographic mention article murdoch re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pgagnon999 has used a sock puppet to remove ci...</td>\n",
       "      <td>1</td>\n",
       "      <td>pgagnon999 has used a sock puppet to remove ci...</td>\n",
       "      <td>pgagnon999 use sock puppet remove cite materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"\\n\\n dhudhi family‎(‎ڈهڈی‎) \\n\\nthe dhudhi‎(‎...</td>\n",
       "      <td>0</td>\n",
       "      <td>dhudhi family the dhudhi are a tribe of panwar...</td>\n",
       "      <td>dhudhi family dhudhi tribe panwar parmar rajpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"\\nre-wording\\naccording to the european commi...</td>\n",
       "      <td>0</td>\n",
       "      <td>re wording according to the european commissio...</td>\n",
       "      <td>word accord european commission change accord ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  \"\\nwell, since i am blocked, i shall temporari...      0   \n",
       "1  \"\\n\\nhahahahaha. typical. \\n\\nthe article is a...      0   \n",
       "2  which you made after i was encouraged by a med...      0   \n",
       "3  i regard you a racist. i will request you be b...      1   \n",
       "4  \"\\n\\na broken chair is not a chair\\na broken c...      0   \n",
       "5  now that you let screwattack how about you fuc...      1   \n",
       "6  national geographic \\n\\nwhy is there no mentio...      0   \n",
       "7  pgagnon999 has used a sock puppet to remove ci...      1   \n",
       "8  \"\\n\\n dhudhi family‎(‎ڈهڈی‎) \\n\\nthe dhudhi‎(‎...      0   \n",
       "9  \"\\nre-wording\\naccording to the european commi...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  well since i am blocked i shall temporarily re...   \n",
       "1  hahahahaha typical the article is about anti p...   \n",
       "2  which you made after i was encouraged by a med...   \n",
       "3  i regard you a racist i will request you be ba...   \n",
       "4  a broken chair is not a chair a broken chord i...   \n",
       "5  now that you let screwattack how about you fuc...   \n",
       "6  national geographic why is there no mention in...   \n",
       "7  pgagnon999 has used a sock puppet to remove ci...   \n",
       "8  dhudhi family the dhudhi are a tribe of panwar...   \n",
       "9  re wording according to the european commissio...   \n",
       "\n",
       "                                        clear_text_2  \n",
       "0  well since block shall temporarily respond whe...  \n",
       "1  hahahahaha typical article anti pedophile acti...  \n",
       "2             make encourage mediator admin make one  \n",
       "3                     regard racist request ban life  \n",
       "4  broken chair chair broken chord chord invert p...  \n",
       "5  let screwattack fuck pedant wikipedia asshole ...  \n",
       "6  national geographic mention article murdoch re...  \n",
       "7  pgagnon999 use sock puppet remove cite materia...  \n",
       "8  dhudhi family dhudhi tribe panwar parmar rajpu...  \n",
       "9  word accord european commission change accord ...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В датасете 159 292 объекта.\n",
    "\n",
    "Пропусков нет, явных дубликатов нет\n",
    "\n",
    "Тексты комментариев на английском\n",
    "\n",
    "В целевом признаке 90% объектов отрицательного класса, то есть в дальнейшем нужно будет учесть это\n",
    "\n",
    "Избавилась от столбца Unnamed, так как он фактически дублирует индексы\n",
    "\n",
    "Для дальнейшего использования 159571 очень большой датасет, поэтому сделала sample\n",
    "\n",
    "Очистила тексты комментариев от ненужных знаков, леммализировала, убрала стоп-слова\n",
    "\n",
    "Сбалансировала данные в целевом признаке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны корректно. Но лемматизацию правильно проводить только с учетом POS-tag.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгтовка и работа с выборками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#разделяю выборки \n",
    "features = corpus.drop(['toxic'], axis=1) \n",
    "target = corpus.toxic\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.2, \n",
    "                                                                              random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=.5,\n",
    "                                                                            random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72000, 3)\n",
      "(72000,)\n",
      "(9000, 3)\n",
      "(9000,)\n",
      "(9000, 3)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "#смотрю размеры выборок:\n",
    "for i in [features_train, target_train, features_valid, target_valid, features_test, target_test]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение 1 и 0 в тренировочной выборке\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: toxic, dtype: float64\n",
      "\n",
      "(14734,)\n",
      "(14734,)\n"
     ]
    }
   ],
   "source": [
    "#уменьшаю кол-во 0 в выборках train\n",
    "\n",
    "corpus_train = corpus.iloc[target_train.index]\n",
    "target_train_0 = corpus_train[corpus_train['toxic'] == 0]['toxic']\n",
    "target_train_1 = corpus_train[corpus_train['toxic'] == 1]['toxic']\n",
    "\n",
    "\n",
    "target_train_0_resample = target_train_0.sample(target_train_1.shape[0], random_state=12345)\n",
    "target_train_resample = pd.concat([target_train_0_resample, target_train_1])\n",
    "\n",
    "features_train_resample = corpus.iloc[target_train_resample.index]\n",
    "\n",
    "features_train_resample, target_train_resample = shuffle(features_train_resample,\n",
    "                                                         target_train_resample,\n",
    "                                                         random_state=12345)\n",
    "\n",
    "features_train_resample = features_train_resample.text \n",
    "\n",
    "print('Соотношение 1 и 0 в тренировочной выборке')\n",
    "print(target_train_resample.value_counts(normalize=True))\n",
    "print()\n",
    "print(features_train_resample.shape)\n",
    "print(target_train_resample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии  0.76\n",
      "лучшие параметры {'lr__C': 10, 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'lbfgs'}\n",
      "\n",
      "CPU times: user 8min 33s, sys: 6min 47s, total: 15min 20s\n",
      "Wall time: 15min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение \n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200])} \n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "\n",
    "print('F1 логистической регрессии ', round(lr_train_f1,2))\n",
    "print('лучшие параметры', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "\n",
    "#тестирование\n",
    "#predictions_test = gscv.predict(features_test.text)\n",
    "#lr_test_f1_1 = f1_score(target_test, predictions_test)\n",
    "#print('F1 логистической регрессии на тесте ', round(lr_test_f1_1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что освоила и применила пайплайн!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений  0.62\n",
      "лучшие параметры {'dtc__class_weight': 'balanced', 'dtc__max_depth': 24, 'dtc__random_state': 12345}\n",
      "\n",
      "CPU times: user 8min 7s, sys: 2.81 s, total: 8min 10s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345]),\n",
    "              'dtc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 дерева решений ', round(dtc_train_f1,2))\n",
    "print('лучшие параметры', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#тестирование\n",
    "#predictions_test = gscv.predict(features_test.text)\n",
    "#dtc_test_f1 = f1_score(target_test, predictions_test)\n",
    "#print('F1 дерева решений на тесте', round(dtc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier  0.72\n",
      "лучшие параметры {'cbc__class_weights': (1, 11), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "\n",
      "CPU times: user 29min 22s, sys: 15.9 s, total: 29min 37s\n",
      "Wall time: 29min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 11)])} \n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 CatBoostClassifier ', round(cbc_train_f1,2))\n",
    "print('лучшие параметры', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "#тестирование\n",
    "#predictions_test = gscv.predict(features_test.text)\n",
    "#cbc_test_f1 = f1_score(target_test, predictions_test)\n",
    "#print('F1 CatBoostClassifier на тесте', round(cbc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> На тестовой выборке нужно измерить только одну – лучшую модель. Сравнение моделей нужно провести только на кросс-валидации (с одним и тем же параметром \"cv\") или только на валидационной выборке.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.757958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.724022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.624130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке\n",
       "LogisticRegression                     0.757958\n",
       "CatBoostClassifier                     0.724022\n",
       "DecisionTreeClassifier                 0.624130"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаю сводную таблицу по показателям F1\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier'\n",
    "        ]\n",
    "        \n",
    "\n",
    "data = {'F1 на обучающей выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1]}\n",
    "        \n",
    "        #'F1 на тестовой выборке': [lr_test_f1_1,\n",
    "         #                               dtc_test_f1,\n",
    "         #                               cbc_test_f1]\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "f1_data.sort_values(by='F1 на обучающей выборке', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "финальный F1 логистической регрессии = 0.77\n"
     ]
    }
   ],
   "source": [
    "#обучение\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} \n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "#тестирование\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 логистической регрессии =', round(lr_test_f1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделила датасет на выборки.\n",
    "\n",
    "Обучила 3 модели с разными гиперпараметрами.\n",
    "\n",
    "Наилучшей моделью стала LogisticRegression, которая на тестовой выборке  показала F1 = 0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я построила модель со значением метрики качества F1 = 0,77. Таким образом, удалось достичь нужного показателя.Интернет-магазину «Викишоп» рекомендуется использовать модель LogisticRegression, которая будет искать токсичные комментарии и отправлять их на модерацию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1368,
    "start_time": "2023-04-08T03:06:33.725Z"
   },
   {
    "duration": 2374,
    "start_time": "2023-04-08T03:07:03.729Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-08T03:07:14.409Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T03:07:31.560Z"
   },
   {
    "duration": 28,
    "start_time": "2023-04-08T03:08:12.549Z"
   },
   {
    "duration": 1860,
    "start_time": "2023-04-08T03:08:55.281Z"
   },
   {
    "duration": 2021,
    "start_time": "2023-04-08T03:09:08.601Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T03:09:26.401Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T03:10:17.957Z"
   },
   {
    "duration": 247,
    "start_time": "2023-04-08T03:10:29.189Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T03:10:59.189Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T03:11:05.869Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T03:11:28.536Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T03:12:36.789Z"
   },
   {
    "duration": 32,
    "start_time": "2023-04-08T03:12:56.049Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T03:14:14.513Z"
   },
   {
    "duration": 50,
    "start_time": "2023-04-08T03:15:37.760Z"
   },
   {
    "duration": 1447,
    "start_time": "2023-04-08T03:15:42.185Z"
   },
   {
    "duration": 2348,
    "start_time": "2023-04-08T03:15:43.634Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T03:15:45.983Z"
   },
   {
    "duration": 65,
    "start_time": "2023-04-08T03:15:46.003Z"
   },
   {
    "duration": 289,
    "start_time": "2023-04-08T03:15:46.070Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-08T03:15:46.360Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-08T03:15:46.390Z"
   },
   {
    "duration": 19,
    "start_time": "2023-04-08T03:15:46.609Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T03:15:47.733Z"
   },
   {
    "duration": 49,
    "start_time": "2023-04-08T03:16:36.561Z"
   },
   {
    "duration": 1362,
    "start_time": "2023-04-08T03:16:43.302Z"
   },
   {
    "duration": 2365,
    "start_time": "2023-04-08T03:16:44.666Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T03:16:47.033Z"
   },
   {
    "duration": 27,
    "start_time": "2023-04-08T03:16:47.050Z"
   },
   {
    "duration": 256,
    "start_time": "2023-04-08T03:16:47.079Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T03:16:47.337Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T03:16:47.371Z"
   },
   {
    "duration": 36,
    "start_time": "2023-04-08T03:16:47.390Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-08T03:16:47.428Z"
   },
   {
    "duration": 253,
    "start_time": "2023-04-08T03:16:47.446Z"
   },
   {
    "duration": 3635,
    "start_time": "2023-04-08T03:18:50.064Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-08T03:19:19.009Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-08T03:21:16.801Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-08T03:22:25.541Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T03:22:51.833Z"
   },
   {
    "duration": 518,
    "start_time": "2023-04-08T03:23:15.313Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:23:54.314Z"
   },
   {
    "duration": 407,
    "start_time": "2023-04-08T03:23:55.365Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T03:24:56.421Z"
   },
   {
    "duration": 530,
    "start_time": "2023-04-08T03:24:57.341Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T03:28:04.933Z"
   },
   {
    "duration": 165,
    "start_time": "2023-04-08T03:28:35.240Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T03:29:13.061Z"
   },
   {
    "duration": 94,
    "start_time": "2023-04-08T03:31:09.308Z"
   },
   {
    "duration": 163,
    "start_time": "2023-04-08T03:31:18.873Z"
   },
   {
    "duration": 90,
    "start_time": "2023-04-08T03:31:50.860Z"
   },
   {
    "duration": 95,
    "start_time": "2023-04-08T03:32:22.571Z"
   },
   {
    "duration": 76,
    "start_time": "2023-04-08T03:32:42.031Z"
   },
   {
    "duration": 87,
    "start_time": "2023-04-08T03:33:00.532Z"
   },
   {
    "duration": 88,
    "start_time": "2023-04-08T03:33:11.340Z"
   },
   {
    "duration": 76,
    "start_time": "2023-04-08T03:33:27.784Z"
   },
   {
    "duration": 72,
    "start_time": "2023-04-08T03:33:59.371Z"
   },
   {
    "duration": 72,
    "start_time": "2023-04-08T03:34:08.537Z"
   },
   {
    "duration": 1262,
    "start_time": "2023-04-08T03:34:38.706Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T03:34:47.980Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T03:35:55.002Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:36:39.403Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:37:57.338Z"
   },
   {
    "duration": 1715,
    "start_time": "2023-04-08T03:38:27.113Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:38:32.135Z"
   },
   {
    "duration": 1170,
    "start_time": "2023-04-08T03:39:06.155Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T03:39:13.055Z"
   },
   {
    "duration": 641,
    "start_time": "2023-04-08T03:39:18.534Z"
   },
   {
    "duration": 30,
    "start_time": "2023-04-08T03:40:39.673Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T03:40:41.022Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T03:40:42.055Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:40:43.362Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:40:45.296Z"
   },
   {
    "duration": 214638,
    "start_time": "2023-04-08T03:40:46.574Z"
   },
   {
    "duration": 108,
    "start_time": "2023-04-08T03:46:09.302Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:46:21.527Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T03:46:33.996Z"
   },
   {
    "duration": 96,
    "start_time": "2023-04-08T03:46:53.342Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T03:48:08.125Z"
   },
   {
    "duration": 74,
    "start_time": "2023-04-08T03:48:37.411Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T03:49:08.576Z"
   },
   {
    "duration": 214595,
    "start_time": "2023-04-08T03:49:16.182Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T03:53:19.389Z"
   },
   {
    "duration": 221980,
    "start_time": "2023-04-08T03:54:25.945Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T03:58:07.927Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T04:02:41.772Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T04:03:01.473Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T04:04:21.073Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T04:04:54.571Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T04:05:25.473Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T04:05:52.251Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T04:07:04.011Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-08T04:07:29.079Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T04:08:48.492Z"
   },
   {
    "duration": 29,
    "start_time": "2023-04-08T04:09:13.538Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-08T04:09:22.651Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T04:11:56.105Z"
   },
   {
    "duration": 33,
    "start_time": "2023-04-08T04:17:28.670Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T04:17:30.031Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T04:17:32.030Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T04:17:33.791Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T04:17:36.131Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T04:17:38.952Z"
   },
   {
    "duration": 1039692,
    "start_time": "2023-04-08T04:17:40.133Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T04:34:59.827Z"
   },
   {
    "duration": 59,
    "start_time": "2023-04-08T04:36:10.467Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T04:36:12.212Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T04:36:15.572Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T04:36:16.803Z"
   },
   {
    "duration": 60,
    "start_time": "2023-04-08T04:36:19.563Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T04:38:31.598Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T04:38:50.697Z"
   },
   {
    "duration": 106,
    "start_time": "2023-04-08T04:38:58.810Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T04:39:40.550Z"
   },
   {
    "duration": 102,
    "start_time": "2023-04-08T04:39:46.004Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T04:41:12.612Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T04:42:41.597Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T04:43:23.525Z"
   },
   {
    "duration": 573,
    "start_time": "2023-04-08T04:43:34.164Z"
   },
   {
    "duration": 568,
    "start_time": "2023-04-08T04:44:43.450Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T04:45:24.215Z"
   },
   {
    "duration": 54,
    "start_time": "2023-04-08T04:45:25.667Z"
   },
   {
    "duration": 292,
    "start_time": "2023-04-08T04:45:48.148Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T04:46:09.286Z"
   },
   {
    "duration": 261,
    "start_time": "2023-04-08T04:46:10.006Z"
   },
   {
    "duration": 111,
    "start_time": "2023-04-08T04:46:41.048Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T04:46:45.995Z"
   },
   {
    "duration": 2003,
    "start_time": "2023-04-08T04:47:29.333Z"
   },
   {
    "duration": 40,
    "start_time": "2023-04-08T04:47:36.349Z"
   },
   {
    "duration": 23,
    "start_time": "2023-04-08T04:47:42.968Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T04:47:54.915Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T04:48:26.527Z"
   },
   {
    "duration": 138,
    "start_time": "2023-04-08T04:52:24.696Z"
   },
   {
    "duration": 121,
    "start_time": "2023-04-08T04:53:15.076Z"
   },
   {
    "duration": 91,
    "start_time": "2023-04-08T04:53:29.064Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T04:55:37.224Z"
   },
   {
    "duration": 746815,
    "start_time": "2023-04-08T04:56:15.472Z"
   },
   {
    "duration": 3233,
    "start_time": "2023-04-08T11:31:56.645Z"
   },
   {
    "duration": 2276,
    "start_time": "2023-04-08T11:31:59.880Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T11:32:05.136Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-08T11:32:06.269Z"
   },
   {
    "duration": 225,
    "start_time": "2023-04-08T11:32:06.997Z"
   },
   {
    "duration": 21,
    "start_time": "2023-04-08T11:32:08.106Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T11:32:09.057Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T11:32:12.843Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T11:32:13.417Z"
   },
   {
    "duration": 195,
    "start_time": "2023-04-08T11:32:18.349Z"
   },
   {
    "duration": 3527,
    "start_time": "2023-04-08T11:32:20.016Z"
   },
   {
    "duration": 28,
    "start_time": "2023-04-08T11:32:23.544Z"
   },
   {
    "duration": 43,
    "start_time": "2023-04-08T11:32:31.216Z"
   },
   {
    "duration": 129,
    "start_time": "2023-04-08T11:33:10.112Z"
   },
   {
    "duration": 222,
    "start_time": "2023-04-08T11:33:17.057Z"
   },
   {
    "duration": 3562,
    "start_time": "2023-04-08T11:33:20.577Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T11:33:24.141Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-08T11:33:26.476Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T11:33:38.897Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T11:34:06.334Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T11:34:09.705Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T11:34:18.738Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:34:23.097Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:34:36.857Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:34:45.176Z"
   },
   {
    "duration": 636,
    "start_time": "2023-04-08T11:34:52.396Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T11:34:58.648Z"
   },
   {
    "duration": 3066,
    "start_time": "2023-04-08T11:35:05.615Z"
   },
   {
    "duration": 755,
    "start_time": "2023-04-08T11:35:08.683Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T11:35:11.256Z"
   },
   {
    "duration": 25,
    "start_time": "2023-04-08T11:35:12.496Z"
   },
   {
    "duration": 225,
    "start_time": "2023-04-08T11:35:13.897Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T11:35:15.057Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T11:35:16.137Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T11:35:17.369Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T11:35:18.957Z"
   },
   {
    "duration": 222,
    "start_time": "2023-04-08T11:35:21.497Z"
   },
   {
    "duration": 3813,
    "start_time": "2023-04-08T11:35:22.577Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T11:35:27.577Z"
   },
   {
    "duration": 45,
    "start_time": "2023-04-08T11:35:29.716Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:35:33.896Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T11:35:35.757Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T11:40:08.077Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T11:40:18.577Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T11:40:31.778Z"
   },
   {
    "duration": 106,
    "start_time": "2023-04-08T11:41:42.738Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T11:42:38.184Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:42:40.702Z"
   },
   {
    "duration": 1,
    "start_time": "2023-04-08T11:42:44.342Z"
   },
   {
    "duration": 131,
    "start_time": "2023-04-08T11:42:49.221Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T11:43:38.488Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T11:43:39.830Z"
   },
   {
    "duration": 941670,
    "start_time": "2023-04-08T11:43:40.688Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T11:59:22.359Z"
   },
   {
    "duration": 85,
    "start_time": "2023-04-08T12:00:52.672Z"
   },
   {
    "duration": 84,
    "start_time": "2023-04-08T12:01:24.748Z"
   },
   {
    "duration": 124,
    "start_time": "2023-04-08T12:02:00.024Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T12:02:09.828Z"
   },
   {
    "duration": 1516,
    "start_time": "2023-04-08T12:04:26.595Z"
   },
   {
    "duration": 839,
    "start_time": "2023-04-08T12:04:28.113Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T12:04:30.636Z"
   },
   {
    "duration": 31,
    "start_time": "2023-04-08T12:04:31.776Z"
   },
   {
    "duration": 224,
    "start_time": "2023-04-08T12:04:32.336Z"
   },
   {
    "duration": 21,
    "start_time": "2023-04-08T12:04:33.176Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T12:04:33.501Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-08T12:04:33.808Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T12:04:34.164Z"
   },
   {
    "duration": 268,
    "start_time": "2023-04-08T12:04:34.961Z"
   },
   {
    "duration": 3758,
    "start_time": "2023-04-08T12:04:35.297Z"
   },
   {
    "duration": 31,
    "start_time": "2023-04-08T12:04:39.057Z"
   },
   {
    "duration": 62,
    "start_time": "2023-04-08T12:04:39.090Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T12:04:40.548Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T12:04:41.656Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T12:04:46.055Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T12:04:47.458Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T12:04:49.429Z"
   },
   {
    "duration": 977317,
    "start_time": "2023-04-08T12:04:50.364Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T12:21:07.684Z"
   },
   {
    "duration": 53,
    "start_time": "2023-04-08T12:21:07.696Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T12:21:07.752Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T12:21:07.771Z"
   },
   {
    "duration": 33,
    "start_time": "2023-04-08T12:21:07.776Z"
   },
   {
    "duration": 35,
    "start_time": "2023-04-08T12:21:07.811Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T12:21:07.847Z"
   },
   {
    "duration": 228350,
    "start_time": "2023-04-08T12:21:07.850Z"
   },
   {
    "duration": 61074,
    "start_time": "2023-04-08T12:24:56.202Z"
   },
   {
    "duration": 373041,
    "start_time": "2023-04-08T12:25:57.278Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-08T12:32:10.320Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T12:33:13.941Z"
   },
   {
    "duration": 94,
    "start_time": "2023-04-08T12:35:36.382Z"
   },
   {
    "duration": 424,
    "start_time": "2023-04-08T12:39:57.580Z"
   },
   {
    "duration": 117020,
    "start_time": "2023-04-08T12:42:40.873Z"
   },
   {
    "duration": 112,
    "start_time": "2023-04-08T12:46:47.610Z"
   },
   {
    "duration": 124027,
    "start_time": "2023-04-08T12:47:00.818Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-08T12:50:06.325Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T12:51:34.000Z"
   },
   {
    "duration": 161783,
    "start_time": "2023-04-08T12:51:38.508Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-08T12:57:13.602Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T12:58:52.611Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T12:59:31.219Z"
   },
   {
    "duration": 618,
    "start_time": "2023-04-08T12:59:47.467Z"
   },
   {
    "duration": 553,
    "start_time": "2023-04-08T13:00:17.638Z"
   },
   {
    "duration": 571,
    "start_time": "2023-04-08T13:00:30.032Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-08T13:01:12.060Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:02:03.956Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T13:02:13.429Z"
   },
   {
    "duration": 103,
    "start_time": "2023-04-08T13:03:00.529Z"
   },
   {
    "duration": 95,
    "start_time": "2023-04-08T13:03:12.969Z"
   },
   {
    "duration": 113,
    "start_time": "2023-04-08T13:03:28.990Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:03:51.771Z"
   },
   {
    "duration": 78,
    "start_time": "2023-04-08T13:05:40.158Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T13:05:53.137Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:06:49.454Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:08:02.757Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-08T13:08:13.986Z"
   },
   {
    "duration": 76397,
    "start_time": "2023-04-08T13:09:58.701Z"
   },
   {
    "duration": 391,
    "start_time": "2023-04-08T13:13:34.972Z"
   },
   {
    "duration": 126462,
    "start_time": "2023-04-08T13:13:56.533Z"
   },
   {
    "duration": 717,
    "start_time": "2023-04-08T13:21:00.158Z"
   },
   {
    "duration": 116004,
    "start_time": "2023-04-08T13:21:43.159Z"
   },
   {
    "duration": 332,
    "start_time": "2023-04-08T13:25:44.488Z"
   },
   {
    "duration": 369,
    "start_time": "2023-04-08T13:26:06.244Z"
   },
   {
    "duration": 745,
    "start_time": "2023-04-08T13:28:06.503Z"
   },
   {
    "duration": 772,
    "start_time": "2023-04-08T13:28:37.144Z"
   },
   {
    "duration": 496,
    "start_time": "2023-04-08T13:29:23.233Z"
   },
   {
    "duration": 97,
    "start_time": "2023-04-08T13:30:01.789Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-08T13:30:32.001Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:31:53.539Z"
   },
   {
    "duration": 19,
    "start_time": "2023-04-08T13:32:21.484Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-08T13:35:51.440Z"
   },
   {
    "duration": 349,
    "start_time": "2023-04-08T13:36:25.634Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T13:43:48.975Z"
   },
   {
    "duration": 76800,
    "start_time": "2023-04-08T13:44:09.215Z"
   },
   {
    "duration": 200461,
    "start_time": "2023-04-08T13:49:17.173Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-08T13:53:19.253Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-08T13:53:28.194Z"
   },
   {
    "duration": 23673,
    "start_time": "2023-04-08T13:53:45.820Z"
   },
   {
    "duration": 87,
    "start_time": "2023-04-08T13:54:12.555Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-08T13:54:25.093Z"
   },
   {
    "duration": 61889,
    "start_time": "2023-04-08T13:54:52.253Z"
   },
   {
    "duration": 61050,
    "start_time": "2023-04-08T13:56:28.627Z"
   },
   {
    "duration": 1554,
    "start_time": "2023-04-08T13:58:03.771Z"
   },
   {
    "duration": 848,
    "start_time": "2023-04-08T13:58:05.328Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T13:58:07.572Z"
   },
   {
    "duration": 27,
    "start_time": "2023-04-08T13:58:08.412Z"
   },
   {
    "duration": 220,
    "start_time": "2023-04-08T13:58:09.312Z"
   },
   {
    "duration": 23,
    "start_time": "2023-04-08T13:58:10.524Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T13:58:11.971Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T13:58:12.524Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-08T13:58:14.410Z"
   },
   {
    "duration": 219,
    "start_time": "2023-04-08T13:58:15.412Z"
   },
   {
    "duration": 3761,
    "start_time": "2023-04-08T13:58:15.743Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T13:58:19.506Z"
   },
   {
    "duration": 56,
    "start_time": "2023-04-08T13:58:20.872Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T13:58:22.312Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T13:58:23.432Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T13:58:24.516Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-08T13:58:25.613Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T13:58:26.717Z"
   },
   {
    "duration": 982281,
    "start_time": "2023-04-08T13:58:27.992Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-08T14:14:50.276Z"
   },
   {
    "duration": 86,
    "start_time": "2023-04-08T14:15:05.829Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T14:15:09.425Z"
   },
   {
    "duration": 1577,
    "start_time": "2023-04-08T14:16:05.745Z"
   },
   {
    "duration": 620,
    "start_time": "2023-04-08T14:16:33.391Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T14:16:35.908Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T14:17:04.346Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T14:17:19.012Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-08T14:17:39.586Z"
   },
   {
    "duration": 145263,
    "start_time": "2023-04-08T14:17:43.253Z"
   },
   {
    "duration": 63951,
    "start_time": "2023-04-08T14:20:39.187Z"
   },
   {
    "duration": 344936,
    "start_time": "2023-04-08T14:22:18.037Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-08T14:28:02.975Z"
   },
   {
    "duration": 168145,
    "start_time": "2023-04-08T14:28:15.365Z"
   },
   {
    "duration": 765181,
    "start_time": "2023-04-08T14:34:55.643Z"
   },
   {
    "duration": 4863,
    "start_time": "2023-04-08T14:56:13.770Z"
   },
   {
    "duration": 612492,
    "start_time": "2023-04-08T14:56:23.072Z"
   },
   {
    "duration": 409307,
    "start_time": "2023-04-08T15:10:14.235Z"
   },
   {
    "duration": 1834268,
    "start_time": "2023-04-08T15:17:03.545Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T15:47:37.815Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-08T15:52:18.587Z"
   },
   {
    "duration": 1761,
    "start_time": "2023-04-08T15:53:28.735Z"
   },
   {
    "duration": 762,
    "start_time": "2023-04-08T15:53:30.499Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-08T15:53:34.575Z"
   },
   {
    "duration": 27,
    "start_time": "2023-04-08T15:53:35.759Z"
   },
   {
    "duration": 245,
    "start_time": "2023-04-08T15:53:37.118Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-08T15:53:37.739Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-08T15:53:38.498Z"
   },
   {
    "duration": 22,
    "start_time": "2023-04-08T15:53:39.168Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-08T15:53:39.793Z"
   },
   {
    "duration": 284,
    "start_time": "2023-04-08T15:53:40.959Z"
   },
   {
    "duration": 3435,
    "start_time": "2023-04-08T15:53:41.513Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-08T15:53:52.846Z"
   },
   {
    "duration": 45,
    "start_time": "2023-04-08T15:53:54.158Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T15:53:56.994Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-08T15:53:58.179Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T15:54:00.094Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-08T15:54:01.398Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-08T15:54:02.734Z"
   },
   {
    "duration": 939022,
    "start_time": "2023-04-08T15:54:06.658Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-08T16:09:45.682Z"
   },
   {
    "duration": 654,
    "start_time": "2023-04-08T16:09:45.696Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-08T16:09:46.353Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-08T16:09:46.372Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T16:09:46.392Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T16:09:46.394Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T16:09:46.395Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T16:09:46.397Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-08T16:09:46.399Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-08T16:11:27.404Z"
   },
   {
    "duration": 756556,
    "start_time": "2023-04-08T16:11:28.813Z"
   },
   {
    "duration": 3584,
    "start_time": "2023-04-09T11:16:11.334Z"
   },
   {
    "duration": 3105,
    "start_time": "2023-04-09T11:16:14.920Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-09T11:16:19.672Z"
   },
   {
    "duration": 32,
    "start_time": "2023-04-09T11:16:19.971Z"
   },
   {
    "duration": 229,
    "start_time": "2023-04-09T11:16:20.424Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-09T11:16:20.894Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T11:16:21.294Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-09T11:16:21.726Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-09T11:16:22.252Z"
   },
   {
    "duration": 332,
    "start_time": "2023-04-09T11:16:23.905Z"
   },
   {
    "duration": 4158,
    "start_time": "2023-04-09T11:16:24.425Z"
   },
   {
    "duration": 27,
    "start_time": "2023-04-09T11:16:28.585Z"
   },
   {
    "duration": 74,
    "start_time": "2023-04-09T11:16:28.613Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-09T11:16:28.690Z"
   },
   {
    "duration": 54,
    "start_time": "2023-04-09T11:16:28.694Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T11:16:28.749Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-09T11:16:28.755Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T11:16:28.786Z"
   },
   {
    "duration": 707070,
    "start_time": "2023-04-09T11:16:30.456Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T11:28:17.527Z"
   },
   {
    "duration": 784,
    "start_time": "2023-04-09T11:28:17.537Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.322Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.324Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.325Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.327Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.329Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.330Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T11:28:18.331Z"
   },
   {
    "duration": 749,
    "start_time": "2023-04-09T11:28:32.541Z"
   },
   {
    "duration": 1091457,
    "start_time": "2023-04-09T11:28:43.523Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-09T11:46:54.982Z"
   },
   {
    "duration": 750,
    "start_time": "2023-04-09T11:47:05.721Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T11:47:08.331Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-09T11:47:13.981Z"
   },
   {
    "duration": 52,
    "start_time": "2023-04-09T11:47:16.559Z"
   },
   {
    "duration": 53,
    "start_time": "2023-04-09T11:48:01.045Z"
   },
   {
    "duration": 74,
    "start_time": "2023-04-09T11:48:47.348Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T11:49:19.312Z"
   },
   {
    "duration": 55,
    "start_time": "2023-04-09T11:49:38.931Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-09T11:51:39.446Z"
   },
   {
    "duration": 70,
    "start_time": "2023-04-09T11:52:05.934Z"
   },
   {
    "duration": 64,
    "start_time": "2023-04-09T11:54:20.115Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-09T11:55:31.629Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-09T11:55:41.798Z"
   },
   {
    "duration": 61,
    "start_time": "2023-04-09T11:57:24.272Z"
   },
   {
    "duration": 533,
    "start_time": "2023-04-09T11:57:43.535Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-09T11:59:57.798Z"
   },
   {
    "duration": 849,
    "start_time": "2023-04-09T12:00:33.766Z"
   },
   {
    "duration": 5772,
    "start_time": "2023-04-09T12:00:53.989Z"
   },
   {
    "duration": 73926,
    "start_time": "2023-04-09T12:01:23.437Z"
   },
   {
    "duration": 65,
    "start_time": "2023-04-09T12:03:17.297Z"
   },
   {
    "duration": 91876,
    "start_time": "2023-04-09T12:05:13.496Z"
   },
   {
    "duration": 508,
    "start_time": "2023-04-09T12:09:01.837Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-09T12:10:06.636Z"
   },
   {
    "duration": 62,
    "start_time": "2023-04-09T12:10:46.116Z"
   },
   {
    "duration": 47,
    "start_time": "2023-04-09T12:11:01.468Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T12:11:04.867Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-09T12:11:35.415Z"
   },
   {
    "duration": 69,
    "start_time": "2023-04-09T12:12:38.895Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-09T12:12:54.722Z"
   },
   {
    "duration": 901093,
    "start_time": "2023-04-09T12:13:02.369Z"
   },
   {
    "duration": 462339,
    "start_time": "2023-04-09T12:28:03.463Z"
   },
   {
    "duration": 56595,
    "start_time": "2023-04-09T12:35:45.804Z"
   },
   {
    "duration": 45,
    "start_time": "2023-04-09T12:36:42.401Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T12:36:42.447Z"
   },
   {
    "duration": 1596193,
    "start_time": "2023-04-09T12:36:52.919Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-09T13:03:29.113Z"
   },
   {
    "duration": 40566,
    "start_time": "2023-04-09T13:03:38.850Z"
   },
   {
    "duration": 14,
    "start_time": "2023-04-09T13:04:32.350Z"
   },
   {
    "duration": 39,
    "start_time": "2023-04-09T13:04:41.517Z"
   },
   {
    "duration": 62,
    "start_time": "2023-04-09T13:06:08.730Z"
   },
   {
    "duration": 804296,
    "start_time": "2023-04-09T13:07:34.421Z"
   },
   {
    "duration": 68,
    "start_time": "2023-04-09T13:30:53.168Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T13:30:55.539Z"
   },
   {
    "duration": 71,
    "start_time": "2023-04-09T13:30:57.017Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T13:31:01.618Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T13:36:56.135Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T13:36:56.138Z"
   },
   {
    "duration": 1408,
    "start_time": "2023-04-09T13:37:04.135Z"
   },
   {
    "duration": 759,
    "start_time": "2023-04-09T13:37:06.195Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T13:37:10.316Z"
   },
   {
    "duration": 33,
    "start_time": "2023-04-09T13:37:11.495Z"
   },
   {
    "duration": 238,
    "start_time": "2023-04-09T13:37:12.147Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-09T13:37:12.715Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-09T13:37:13.362Z"
   },
   {
    "duration": 21,
    "start_time": "2023-04-09T13:37:13.916Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-09T13:37:14.410Z"
   },
   {
    "duration": 256,
    "start_time": "2023-04-09T13:37:15.835Z"
   },
   {
    "duration": 3865,
    "start_time": "2023-04-09T13:37:16.335Z"
   },
   {
    "duration": 30,
    "start_time": "2023-04-09T13:37:20.202Z"
   },
   {
    "duration": 75,
    "start_time": "2023-04-09T13:37:20.233Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T13:37:20.310Z"
   },
   {
    "duration": 16,
    "start_time": "2023-04-09T13:37:20.316Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-09T13:37:20.334Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-09T13:37:20.343Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T13:37:20.363Z"
   },
   {
    "duration": 1089422,
    "start_time": "2023-04-09T13:37:20.369Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-09T13:55:29.793Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T13:55:29.803Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T13:55:29.810Z"
   },
   {
    "duration": 112,
    "start_time": "2023-04-09T13:55:29.816Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T13:55:29.930Z"
   },
   {
    "duration": 77,
    "start_time": "2023-04-09T13:55:29.935Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-09T13:55:30.013Z"
   },
   {
    "duration": 921956,
    "start_time": "2023-04-09T13:55:30.018Z"
   },
   {
    "duration": 490987,
    "start_time": "2023-04-09T14:10:51.977Z"
   },
   {
    "duration": 1782851,
    "start_time": "2023-04-09T14:19:02.965Z"
   },
   {
    "duration": 20,
    "start_time": "2023-04-09T14:48:45.819Z"
   },
   {
    "duration": 6405,
    "start_time": "2023-04-09T15:53:45.878Z"
   },
   {
    "duration": 805898,
    "start_time": "2023-04-09T15:53:56.705Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
